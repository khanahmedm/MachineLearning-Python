{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Foundation\n",
    "\n",
    "## Course 3, Part b: K-Nearest Neighbor LAB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction and Learning Goals\n",
    "\n",
    "In this lab, we explore classification using the K-Nearest Neighbors approach. We use a customer churn dataset from the telecom industry which includes customer data, usage of long-distance, data usage, monthly revenue, type of offerings, and other services purchased by customers. The data, based on a fictional telecom firm, include several Excel files which have been combined and are available in the course materials. We are using the subset of customers who have phone accounts. Since the data include a mix of numeric, categorical, and ordinal variables, we will load this data and do some preprocessing, then use K-nearest neighbors to predict customer churn rates.\n",
    "\n",
    "After completing this lab, you should have a working understanding of how to preprocess a variety of variables in order to apply the K-Nearest Neighbors algorithm, understand how to choose K, and understand how to evaluate model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np, matplotlib.pyplot as plt, os, sys, seaborn as sns\n",
    "os.chdir('data')\n",
    "from datasetup import churndata, colors, palette\n",
    "sns.set_palette(palette)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "\n",
    "* We begin by importing the data. Examine the columns and data.\n",
    "* Notice that the data contains a unique ID, an indicator for phone customer status, total lifetime value, total revenue, and a bank-estimated churn score. We will not be using these features, so they can be dropped from the data.\n",
    "* Begin by taking an initial look at the data, including both numeric and non-numeric features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "df = churndata.drop(columns=['id', 'phone', 'total_revenue', 'cltv', 'churn_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(df.describe(),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include='object')\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "\n",
    "* Identify which variables are binary, categorical and not ordinal, categorical and ordinal, and numeric.  The non-numeric features will need to be encoded using methods we have discussed in the course.\n",
    "* Start by identifying the number of unique values each variable takes, then create list variables for categorical, numeric, binary, and ordinal variables. \n",
    "* Note that the variable 'months' can be treated as numeric, but it may be more convenient to transform it to an ordinal variable.\n",
    "* For the other categorical variables, examine their values to determine which may be encoded ordinally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "df_uniques = pd.DataFrame([[i, len(df[i].unique())] for i in df.columns], columns=['Variable', 'Unique Values']).set_index('Variable')\n",
    "df_uniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_variables = list(df_uniques[df_uniques['Unique Values'] == 2].index)\n",
    "binary_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_variables = list(df_uniques[(6 >= df_uniques['Unique Values']) & (df_uniques['Unique Values'] > 2)].index)\n",
    "categorical_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[[i, list(df[i].unique())] for i in categorical_variables]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinal_variables = ['contract', 'satisfaction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['months'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinal_variables.append('months')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_variables = list(set(df.columns) - set(ordinal_variables) - set(categorical_variables) - set(binary_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[numeric_variables].hist(color=colors[0], figsize=(12, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['months'] = pd.cut(df['months'], bins=5)\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "* Having set up the variables, remember that the K-nearest neighbors algorithm uses distance and hence requires scaled data. \n",
    "* Scale the data using one of the scaling methods discussed in the course.\n",
    "* Save the processed dataframe as a comma-separated file: 'churndata_processed.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "from sklearn.preprocessing import LabelBinarizer, LabelEncoder, OrdinalEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb, le = LabelBinarizer(), LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in ordinal_variables:\n",
    "    df[column] = le.fit_transform(df[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[ordinal_variables].astype('category').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in binary_variables:\n",
    "    df[column] = lb.fit_transform(df[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_variables = list(set(categorical_variables) - set(ordinal_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, columns = categorical_variables, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "mm = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in [ordinal_variables + numeric_variables]:\n",
    "    df[column] = mm.fit_transform(df[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(df.describe().T, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### END SOLUTION\n",
    "\n",
    "# Save a copy of the processed data for later use\n",
    "outputfile = 'churndata_processed.csv'\n",
    "df.to_csv(outputfile, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "* Now that the data are encoded and scaled, separate the features (X) from the target (y, churn_value). \n",
    "* Split the sample into training and test samples, with the test sample representing 40% of observations.\n",
    "* Estimate a K-Nearest Neighbors model, using K=3.\n",
    "* Examine the Precision, Recall, F-1 Score, and Accuracy of the classification.\n",
    "* Use a graphic to illustrate the Confusion Matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up X and y variables\n",
    "y, X = df['churn_value'], df.drop(columns='churn_value')\n",
    "# Split the data into training and test samples\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate KNN model and report outcomes\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn = knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "# Preciision, recall, f-score from the multi-class support function\n",
    "print(classification_report(y_test, y_pred))\n",
    "print('Accuracy score: ', round(accuracy_score(y_test, y_pred), 2))\n",
    "print('F1 Score: ', round(f1_score(y_test, y_pred), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix\n",
    "sns.set_palette(sns.color_palette(colors))\n",
    "_, ax = plt.subplots(figsize=(12,12))\n",
    "ax = sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='d', cmap=colors, annot_kws={\"size\": 40, \"weight\": \"bold\"})  \n",
    "labels = ['False', 'True']\n",
    "ax.set_xticklabels(labels, fontsize=25);\n",
    "ax.set_yticklabels(labels[::-1], fontsize=25);\n",
    "ax.set_ylabel('Prediction', fontsize=30);\n",
    "ax.set_xlabel('Ground Truth', fontsize=30)\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5\n",
    "* Using the same split of training and test samples, estimate another K-Nearest Neighbors model\n",
    "* This time, use K=5 and weight the results by distance\n",
    "* Again, examine the Precision, Recall, F-1 Score, and Accuracy of the classification, and visualize the Confusion Matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "knn = KNeighborsClassifier(n_neighbors=5, weights='distance')\n",
    "knn = knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "# Preciision, recall, f-score from the multi-class support function\n",
    "print(classification_report(y_test, y_pred))\n",
    "print('Accuracy score: ', round(accuracy_score(y_test, y_pred), 2))\n",
    "print('F1 Score: ', round(f1_score(y_test, y_pred), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix\n",
    "_, ax = plt.subplots(figsize=(12,12))\n",
    "ax = sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='d', cmap=colors, annot_kws={\"size\": 40, \"weight\": \"bold\"})  \n",
    "labels = ['False', 'True']\n",
    "ax.set_xticklabels(labels, fontsize=25);\n",
    "ax.set_yticklabels(labels[::-1], fontsize=25);\n",
    "ax.set_ylabel('Prediction', fontsize=30);\n",
    "ax.set_xlabel('Ground Truth', fontsize=30)\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6\n",
    "* To determine the right value for K, examing results for values of K from 1 to 40.\n",
    "* This time, focus on two measures, the F-1 Score, and the Error Rate (1-Accuracy)\n",
    "* Generate charts which plot each of these measures as a function of K. \n",
    "* What do these charts suggest about the optimal value for K?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "max_k = 40\n",
    "f1_scores = list()\n",
    "error_rates = list() # 1-accuracy\n",
    "\n",
    "for k in range(1, max_k):\n",
    "    \n",
    "    knn = KNeighborsClassifier(n_neighbors=k, weights='distance')\n",
    "    knn = knn.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = knn.predict(X_test)\n",
    "    f1 = f1_score(y_pred, y_test)\n",
    "    f1_scores.append((k, round(f1_score(y_test, y_pred), 4)))\n",
    "    error = 1-round(accuracy_score(y_test, y_pred), 4)\n",
    "    error_rates.append((k, error))\n",
    "    \n",
    "f1_results = pd.DataFrame(f1_scores, columns=['K', 'F1 Score'])\n",
    "error_results = pd.DataFrame(error_rates, columns=['K', 'Error Rate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot F1 results\n",
    "sns.set_context('talk')\n",
    "sns.set_style('ticks')\n",
    "\n",
    "plt.figure(dpi=300)\n",
    "ax = f1_results.set_index('K').plot(color=colors[0], figsize=(12, 12), linewidth=6)\n",
    "ax.set(xlabel='K', ylabel='F1 Score')\n",
    "ax.set_xticks(range(1, max_k, 2));\n",
    "plt.title('KNN F1 Score')\n",
    "plt.savefig('knn_f1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Accuracy (Error Rate) results\n",
    "sns.set_context('talk')\n",
    "sns.set_style('ticks')\n",
    "\n",
    "plt.figure(dpi=300)\n",
    "ax = error_results.set_index('K').plot(color=colors[0], figsize=(12, 12), linewidth=6)\n",
    "ax.set(xlabel='K', ylabel='Error Rate')\n",
    "ax.set_xticks(range(1, max_k, 2))\n",
    "plt.title('KNN Elbow Curve')\n",
    "plt.savefig('knn_elbow.png')\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Machine Learning Foundation (C) 2020 IBM Corporation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
